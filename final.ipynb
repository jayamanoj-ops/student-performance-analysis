{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31956cc6-6987-4ba4-a8a1-9564a0369f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vtu_pipeline_final_fixed.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import date, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Versionâ€‘proof OneHotEncoder\n",
    "def make_ohe():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)  # sklearn >= 1.2\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)         # sklearn <= 1.1\n",
    "\n",
    "# Try XGBoost; fallback to RF\n",
    "USE_XGB = True\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except Exception:\n",
    "    USE_XGB = False\n",
    "\n",
    "# Try SHAP; fallback to feature importance plot\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except Exception:\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "DEPARTMENTS = [\"CSE\", \"ISE\", \"ECE\", \"EEE\", \"MECH\"]\n",
    "N_STUDENTS_PER_DEPT = 120\n",
    "SEMESTER = 5\n",
    "WEEKS = 16\n",
    "SEM_START = date(2025, 8, 1)\n",
    "WEEK_STARTS = [SEM_START + timedelta(weeks=i) for i in range(WEEKS)]\n",
    "FESTIVAL_WEEKS = {date(2025, 11, 3)}  # e.g., Diwali week\n",
    "\n",
    "PASS_MARK = 50\n",
    "BASELINE_PASS_RATE = 0.70  # 70%\n",
    "\n",
    "DEPT_COURSES = {\n",
    "    \"CSE\": [\n",
    "        (\"Software Engineering\", 4, \"Theory\"),\n",
    "        (\"Computer Networks\", 4, \"Theory\"),\n",
    "        (\"DBMS\", 4, \"Theory\"),\n",
    "        (\"Automata Theory\", 4, \"Theory\"),\n",
    "        (\"Machine Learning\", 4, \"Theory\"),\n",
    "        (\"CN Lab\", 2, \"Lab\"),\n",
    "        (\"DBMS Lab\", 2, \"Lab\")\n",
    "    ],\n",
    "    \"ISE\": [\n",
    "        (\"Software Engineering\", 4, \"Theory\"),\n",
    "        (\"Data Communication\", 4, \"Theory\"),\n",
    "        (\"DBMS\", 4, \"Theory\"),\n",
    "        (\"Automata Theory\", 4, \"Theory\"),\n",
    "        (\"Data Mining\", 4, \"Theory\"),\n",
    "        (\"CN Lab\", 2, \"Lab\"),\n",
    "        (\"DBMS Lab\", 2, \"Lab\")\n",
    "    ],\n",
    "    \"ECE\": [\n",
    "        (\"Digital Communication\", 4, \"Theory\"),\n",
    "        (\"Microprocessors\", 4, \"Theory\"),\n",
    "        (\"Control Systems\", 4, \"Theory\"),\n",
    "        (\"VLSI Design\", 4, \"Theory\"),\n",
    "        (\"Signals & Systems\", 4, \"Theory\"),\n",
    "        (\"VLSI Lab\", 2, \"Lab\"),\n",
    "        (\"DSP Lab\", 2, \"Lab\")\n",
    "    ],\n",
    "    \"EEE\": [\n",
    "        (\"Power Systems\", 4, \"Theory\"),\n",
    "        (\"Control Systems\", 4, \"Theory\"),\n",
    "        (\"Microcontrollers\", 4, \"Theory\"),\n",
    "        (\"Electrical Machines\", 4, \"Theory\"),\n",
    "        (\"Power Electronics\", 4, \"Theory\"),\n",
    "        (\"Machines Lab\", 2, \"Lab\"),\n",
    "        (\"Power Electronics Lab\", 2, \"Lab\")\n",
    "    ],\n",
    "    \"MECH\": [\n",
    "        (\"Dynamics of Machines\", 4, \"Theory\"),\n",
    "        (\"Design of Machine Elements\", 4, \"Theory\"),\n",
    "        (\"Heat Transfer\", 4, \"Theory\"),\n",
    "        (\"Fluid Mechanics\", 4, \"Theory\"),\n",
    "        (\"Manufacturing Process\", 4, \"Theory\"),\n",
    "        (\"Thermal Lab\", 2, \"Lab\"),\n",
    "        (\"FM Lab\", 2, \"Lab\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "OUT = Path(\".\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def clipped_normal(mu, sigma, low, high, size=None):\n",
    "    x = np.random.normal(mu, sigma, size)\n",
    "    return np.clip(x, low, high)\n",
    "\n",
    "def linear_trend(arr):\n",
    "    x = np.arange(len(arr))\n",
    "    if len(arr) < 2 or np.all(arr == arr[0]):\n",
    "        return 0.0\n",
    "    return float(np.polyfit(x, arr, 1)[0])\n",
    "\n",
    "def choose_section():\n",
    "    return random.choice(list(\"ABCDE\"))\n",
    "\n",
    "def choose_gender():\n",
    "    return random.choice([\"Male\", \"Female\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Students & Courses\n",
    "# -----------------------------\n",
    "students, courses = [], []\n",
    "cid = 1\n",
    "for dept in DEPARTMENTS:\n",
    "    for cname, credits, ctype in DEPT_COURSES[dept]:\n",
    "        courses.append({\n",
    "            \"CourseID\": f\"C{cid:03d}\",\n",
    "            \"CourseName\": cname,\n",
    "            \"Department\": dept,\n",
    "            \"Semester\": SEMESTER,\n",
    "            \"Credits\": credits,\n",
    "            \"CourseType\": ctype\n",
    "        })\n",
    "        cid += 1\n",
    "\n",
    "sid_counter = 1\n",
    "for dept in DEPARTMENTS:\n",
    "    for _ in range(N_STUDENTS_PER_DEPT):\n",
    "        # Tri-modal latent ability for clearer bands\n",
    "        ability_mode = np.random.choice([\"low\",\"mid\",\"high\"], p=[0.33,0.34,0.33])\n",
    "        if ability_mode == \"low\":\n",
    "            latent_ability = np.random.normal(0.35, 0.07)\n",
    "        elif ability_mode == \"mid\":\n",
    "            latent_ability = np.random.normal(0.55, 0.07)\n",
    "        else:\n",
    "            latent_ability = np.random.normal(0.78, 0.07)\n",
    "        latent_ability = float(np.clip(latent_ability, 0.15, 0.95))\n",
    "\n",
    "        students.append({\n",
    "            \"StudentID\": f\"S{sid_counter:04d}\",\n",
    "            \"Department\": dept,\n",
    "            \"Section\": choose_section(),\n",
    "            \"Age\": int(np.random.randint(18, 25)),\n",
    "            \"Gender\": choose_gender(),\n",
    "            \"LatentAbility\": latent_ability,\n",
    "            \"PriorGPA\": round(np.clip(np.random.normal(6.8 + 2.2*latent_ability, 0.6), 5.0, 9.8), 1)\n",
    "        })\n",
    "        sid_counter += 1\n",
    "\n",
    "students_df = pd.DataFrame(students)\n",
    "courses_df = pd.DataFrame(courses)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Enrollments, Assessments, LMS\n",
    "# -----------------------------\n",
    "enrollments, assessments, lms_rows = [], [], []\n",
    "\n",
    "for _, s in students_df.iterrows():\n",
    "    sid = s[\"StudentID\"]; dept = s[\"Department\"]; ability = s[\"LatentAbility\"]\n",
    "    dept_courses = courses_df[courses_df[\"Department\"] == dept]\n",
    "    base_attendance = np.clip(60 + 30*ability + np.random.normal(0, 8), 35, 96)\n",
    "\n",
    "    for _, c in dept_courses.iterrows():\n",
    "        cid = c[\"CourseID\"]; ctype = c[\"CourseType\"]\n",
    "        attendance = float(np.clip(np.random.normal(base_attendance, 6), 35, 96))\n",
    "        assign_avg = float(np.clip(50 + 40*ability + 0.15*attendance + np.random.normal(0, 8), 20, 98))\n",
    "        quiz_avg   = float(np.clip(48 + 40*ability + 0.12*attendance + np.random.normal(0, 10), 10, 98))\n",
    "        ia1 = float(np.clip(0.35*attendance + 0.35*assign_avg + 0.30*quiz_avg + np.random.normal(0, 6), 0, 100))\n",
    "        ia2 = float(np.clip(0.40*attendance + 0.30*assign_avg + 0.30*quiz_avg + np.random.normal(0, 6), 0, 100))\n",
    "        ia3 = float(np.clip(0.40*attendance + 0.25*assign_avg + 0.35*quiz_avg + np.random.normal(0, 6), 0, 100))\n",
    "        project = float(np.clip(55 + 45*ability + np.random.normal(0, 10), 20, 98)) if ctype==\"Lab\" else np.nan\n",
    "\n",
    "        # LMS weekly activity with festival dip and late push\n",
    "        for wk in WEEK_STARTS:\n",
    "            outage = wk in FESTIVAL_WEEKS\n",
    "            week_idx = (wk - WEEK_STARTS[0]).days // 7\n",
    "            late_push = 1.0 + 0.02*max(0, week_idx - 8)\n",
    "            base_lambda = (3 if ctype==\"Theory\" else 2) * (0.8 + 0.6*ability) * late_push\n",
    "            logins = 0 if outage else np.random.poisson(max(0.5, base_lambda))\n",
    "            time_mins = 0 if outage else max(0, np.random.normal((85 if ctype==\"Theory\" else 70)*(0.8+0.6*ability), 30))\n",
    "            videos = 0 if outage else np.random.poisson(max(0.5, (3 if ctype==\"Theory\" else 2)*(0.8+0.6*ability)))\n",
    "            posts = 0 if outage else np.random.poisson(max(0.3, 1*(0.8+0.4*ability)))\n",
    "\n",
    "            lms_rows.append({\n",
    "                \"StudentID\": sid, \"CourseID\": cid, \"WeekStart\": wk,\n",
    "                \"LMSLogins\": int(logins), \"TimeOnPlatformMins\": float(round(time_mins,1)),\n",
    "                \"VideosWatched\": int(videos), \"ForumPosts\": int(posts)\n",
    "            })\n",
    "\n",
    "        # Final score strongly tied to IA2/IA3 + CA + project (lab)\n",
    "        final_score = (\n",
    "            0.35*ia2 + 0.25*ia3 + 0.18*assign_avg + 0.10*quiz_avg +\n",
    "            (0.12*project if ctype==\"Lab\" else 0) + np.random.normal(0, 6)\n",
    "        )\n",
    "        final_score = float(np.clip(final_score, 25, 98))\n",
    "\n",
    "        enrollments.append({\n",
    "            \"StudentID\": sid, \"CourseID\": cid,\n",
    "            \"AttendanceRate\": round(attendance,1),\n",
    "            \"AssignmentScoreAvg\": round(assign_avg,1),\n",
    "            \"QuizScoreAvg\": round(quiz_avg,1),\n",
    "            \"ProjectScore\": round(project,1) if not np.isnan(project) else np.nan\n",
    "        })\n",
    "\n",
    "        assessments.append({\n",
    "            \"StudentID\": sid, \"CourseID\": cid,\n",
    "            \"IA1\": round(ia1,1), \"IA2\": round(ia2,1), \"IA3\": round(ia3,1),\n",
    "            \"FinalExamScore\": round(final_score,1)\n",
    "        })\n",
    "\n",
    "enrollments_df = pd.DataFrame(enrollments)\n",
    "assessments_df = pd.DataFrame(assessments)\n",
    "lms_df = pd.DataFrame(lms_rows)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Feature engineering (25+ features)\n",
    "# -----------------------------\n",
    "def aggregate_lms(lms: pd.DataFrame) -> pd.DataFrame:\n",
    "    aggs = lms.groupby([\"StudentID\",\"CourseID\"]).agg(\n",
    "        logins_mean=(\"LMSLogins\",\"mean\"),\n",
    "        logins_std=(\"LMSLogins\",\"std\"),\n",
    "        time_mean=(\"TimeOnPlatformMins\",\"mean\"),\n",
    "        time_std=(\"TimeOnPlatformMins\",\"std\"),\n",
    "        videos_mean=(\"VideosWatched\",\"mean\"),\n",
    "        posts_mean=(\"ForumPosts\",\"mean\"),\n",
    "        weeks_active=(\"LMSLogins\",lambda x: int((x>0).sum())),\n",
    "        weeks_inactive=(\"LMSLogins\",lambda x: int((x==0).sum()))\n",
    "    ).reset_index()\n",
    "\n",
    "    trends = []\n",
    "    early_late = []\n",
    "    for (sid, cid), grp in lms.groupby([\"StudentID\",\"CourseID\"]):\n",
    "        g = grp.sort_values(\"WeekStart\")\n",
    "        early = g.head(4)[\"LMSLogins\"].sum()\n",
    "        late  = g.tail(4)[\"LMSLogins\"].sum()\n",
    "        edrop = (early - late) / (early + 1e-6)\n",
    "        trends.append({\n",
    "            \"StudentID\": sid, \"CourseID\": cid,\n",
    "            \"logins_trend\": linear_trend(g[\"LMSLogins\"].values),\n",
    "            \"time_trend\": linear_trend(g[\"TimeOnPlatformMins\"].values)\n",
    "        })\n",
    "        early_late.append({\n",
    "            \"StudentID\": sid, \"CourseID\": cid,\n",
    "            \"engagement_drop_rate\": edrop\n",
    "        })\n",
    "    trends = pd.DataFrame(trends)\n",
    "    early_late = pd.DataFrame(early_late)\n",
    "\n",
    "    out = aggs.merge(trends, on=[\"StudentID\",\"CourseID\"], how=\"left\") \\\n",
    "              .merge(early_late, on=[\"StudentID\",\"CourseID\"], how=\"left\")\n",
    "    out[\"engagement_index\"] = (\n",
    "        0.4*out[\"logins_mean\"] +\n",
    "        0.4*(out[\"time_mean\"]/60.0) +\n",
    "        0.1*out[\"videos_mean\"] +\n",
    "        0.1*out[\"posts_mean\"]\n",
    "    )\n",
    "    return out\n",
    "\n",
    "lms_agg = aggregate_lms(lms_df)\n",
    "\n",
    "feat = enrollments_df.merge(assessments_df, on=[\"StudentID\",\"CourseID\"], how=\"left\") \\\n",
    "                     .merge(lms_agg, on=[\"StudentID\",\"CourseID\"], how=\"left\") \\\n",
    "                     .merge(courses_df[[\"CourseID\",\"Department\",\"Credits\",\"CourseType\",\"CourseName\"]], on=\"CourseID\", how=\"left\") \\\n",
    "                     .merge(students_df[[\"StudentID\",\"Section\",\"Age\",\"Gender\",\"PriorGPA\"]], on=\"StudentID\", how=\"left\")\n",
    "\n",
    "feat[\"IA_avg\"] = feat[[\"IA1\",\"IA2\",\"IA3\"]].mean(axis=1)\n",
    "feat[\"IA_trend\"] = feat[\"IA3\"] - feat[\"IA1\"]\n",
    "feat[\"attendance_flag_lt75\"] = (feat[\"AttendanceRate\"] < 75).astype(int)\n",
    "feat[\"ia2_below60\"] = (feat[\"IA2\"] < 60).astype(int)\n",
    "feat[\"quiz_below60\"] = (feat[\"QuizScoreAvg\"] < 60).astype(int)\n",
    "feat[\"assign_below60\"] = (feat[\"AssignmentScoreAvg\"] < 60).astype(int)\n",
    "feat[\"lab_weak\"] = ((feat[\"CourseType\"]==\"Lab\") & (feat[\"ProjectScore\"] < 65)).astype(int)\n",
    "feat[\"inactivity_ratio\"] = feat[\"weeks_inactive\"] / (feat[\"weeks_active\"] + feat[\"weeks_inactive\"]).replace(0,1)\n",
    "feat[\"age_norm\"] = (feat[\"Age\"] - feat[\"Age\"].mean())/feat[\"Age\"].std(ddof=0)\n",
    "feat[\"attendance_volatility\"] = feat[\"logins_std\"].fillna(0) / (feat[\"logins_mean\"].fillna(0) + 1e-6)\n",
    "feat[\"prior_coursework_score\"] = np.clip(55 + 5*feat[\"PriorGPA\"] + np.random.normal(0,6,len(feat)), 40, 98)\n",
    "feat[\"lab_theory_gap\"] = np.where(feat[\"CourseType\"]==\"Lab\",\n",
    "                                  feat[\"ProjectScore\"] - feat[\"QuizScoreAvg\"],\n",
    "                                  feat[\"QuizScoreAvg\"] - feat[\"AssignmentScoreAvg\"])\n",
    "\n",
    "feat[\"PerformanceBand\"] = pd.cut(\n",
    "    feat[\"FinalExamScore\"],\n",
    "    bins=[-0.1, 55, 75, 100],\n",
    "    labels=[\"Low\",\"Medium\",\"High\"]\n",
    ")\n",
    "\n",
    "# Save raw tables (strip latent ability)\n",
    "students_export = students_df.drop(columns=[\"LatentAbility\"])\n",
    "students_export.to_csv(\"students.csv\", index=False)\n",
    "courses_df.to_csv(\"courses.csv\", index=False)\n",
    "enrollments_df.to_csv(\"enrollments.csv\", index=False)\n",
    "assessments_df.to_csv(\"assessments.csv\", index=False)\n",
    "lms_df.to_csv(\"lms.csv\", index=False)\n",
    "feat.to_csv(\"features.csv\", index=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Modeling\n",
    "# -----------------------------\n",
    "numeric_cols = [\n",
    "    \"AttendanceRate\",\"AssignmentScoreAvg\",\"QuizScoreAvg\",\"ProjectScore\",\n",
    "    \"IA1\",\"IA2\",\"IA3\",\"IA_avg\",\"IA_trend\",\n",
    "    \"logins_mean\",\"logins_std\",\"time_mean\",\"time_std\",\n",
    "    \"videos_mean\",\"posts_mean\",\"weeks_active\",\"weeks_inactive\",\n",
    "    \"logins_trend\",\"time_trend\",\"engagement_index\",\"engagement_drop_rate\",\n",
    "    \"inactivity_ratio\",\"attendance_volatility\",\"Credits\",\"PriorGPA\",\n",
    "    \"prior_coursework_score\",\"lab_theory_gap\",\"age_norm\",\n",
    "    \"attendance_flag_lt75\",\"ia2_below60\",\"quiz_below60\",\"assign_below60\",\"lab_weak\"\n",
    "]\n",
    "numeric_cols = list(dict.fromkeys(numeric_cols))\n",
    "cat_cols = [\"Department\",\"CourseType\",\"Section\",\"Gender\"]\n",
    "\n",
    "model_df = feat.dropna(subset=[\"PerformanceBand\"]).copy()\n",
    "X = model_df[numeric_cols + cat_cols]\n",
    "y = model_df[\"PerformanceBand\"]\n",
    "\n",
    "ohe = make_ohe()\n",
    "ct = ColumnTransformer([\n",
    "    (\"num\",\"passthrough\", numeric_cols),\n",
    "    (\"cat\", ohe, cat_cols)\n",
    "])\n",
    "\n",
    "if USE_XGB:\n",
    "    clf = XGBClassifier(\n",
    "        n_estimators=600,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.06,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "else:\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=900,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "pipe = Pipeline([(\"prep\", ct), (\"clf\", clf)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"\\nClass distribution (train):\")\n",
    "print(y_train.value_counts(normalize=True).round(3))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Balanced accuracy:\", round(balanced_accuracy_score(y_test, y_pred), 4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "joblib.dump(pipe, \"student_perf_clf.joblib\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Early Warning Alerts\n",
    "# -----------------------------\n",
    "proba_all = pipe.predict_proba(X)\n",
    "classes = list(pipe.classes_)\n",
    "p_low = proba_all[:, classes.index(\"Low\")]\n",
    "\n",
    "alerts_df = model_df[[\"StudentID\",\"CourseID\"]].copy()\n",
    "alerts_df[\"PredictedBand\"] = pipe.predict(X)\n",
    "alerts_df[\"PLow\"] = np.round(p_low, 3)\n",
    "\n",
    "def risk_bucket(p):\n",
    "    if p >= 0.60: return \"High\"\n",
    "    if p >= 0.35: return \"Medium\"\n",
    "    return \"Low\"\n",
    "\n",
    "alerts_df[\"RiskLevel\"] = alerts_df[\"PLow\"].apply(risk_bucket)\n",
    "\n",
    "# Assign alert dates skewed to mid/late term (after IA1)\n",
    "alert_weeks = WEEK_STARTS[5:]  # from week 6 onwards\n",
    "alerts_df[\"AlertDate\"] = [random.choice(alert_weeks) for _ in range(len(alerts_df))]\n",
    "\n",
    "# Attach drivers for reasons\n",
    "subset = model_df[[\"StudentID\",\"CourseID\",\"AttendanceRate\",\"IA2\",\"QuizScoreAvg\",\"engagement_index\",\"engagement_drop_rate\"]]\n",
    "alerts_df = alerts_df.merge(subset, on=[\"StudentID\",\"CourseID\"], how=\"left\")\n",
    "\n",
    "def reason(row):\n",
    "    r = []\n",
    "    if row[\"AttendanceRate\"] < 60: r.append(\"Low attendance\")\n",
    "    if row[\"IA2\"] < 55: r.append(\"Weak IA2\")\n",
    "    if row[\"QuizScoreAvg\"] < 55: r.append(\"Low quiz avg\")\n",
    "    if row[\"engagement_index\"] < 3.0: r.append(\"Low LMS engagement\")\n",
    "    if row[\"engagement_drop_rate\"] > 0.25: r.append(\"Engagement dropped\")\n",
    "    return \", \".join(r) if r else \"Stable\"\n",
    "\n",
    "alerts_df[\"RiskReason\"] = alerts_df.apply(reason, axis=1)\n",
    "\n",
    "alerts_export = alerts_df[[\n",
    "    \"StudentID\",\"CourseID\",\"PredictedBand\",\"PLow\",\"RiskLevel\",\"RiskReason\",\"AlertDate\"\n",
    "]]\n",
    "alerts_export.to_csv(\"alerts.csv\", index=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Recommendations\n",
    "# -----------------------------\n",
    "def recommend(row):\n",
    "    recs = []\n",
    "    if row[\"AttendanceRate\"] < 75:\n",
    "        recs.append(\"Attendance counselling + buddy system\")\n",
    "    if row[\"IA2\"] < 60:\n",
    "        recs.append(\"IA2 remedial + topic-wise practice set\")\n",
    "    if row[\"QuizScoreAvg\"] < 60:\n",
    "        recs.append(\"Concept videos + micro-quizzes\")\n",
    "    if row[\"engagement_index\"] < 3.0:\n",
    "        recs.append(\"LMS study plan (3x/week) + tutor check-ins\")\n",
    "    if row[\"engagement_drop_rate\"] > 0.25:\n",
    "        recs.append(\"Motivation check-in + peer group project\")\n",
    "    if not recs:\n",
    "        recs.append(\"Advanced project / enrichment tasks\")\n",
    "    return \"; \".join(recs)\n",
    "\n",
    "recs_df = subset.copy()\n",
    "recs_df[\"RecommendedAction\"] = recs_df.apply(recommend, axis=1)\n",
    "recs_export = recs_df[[\"StudentID\",\"CourseID\",\"RecommendedAction\"]]\n",
    "recs_export.to_csv(\"recommendations.csv\", index=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Explainability (global)\n",
    "# -----------------------------\n",
    "if SHAP_AVAILABLE and USE_XGB:\n",
    "    # SHAP on transformed sample\n",
    "    explainer = shap.TreeExplainer(pipe.named_steps[\"clf\"])\n",
    "    Xt_train = pipe.named_steps[\"prep\"].fit_transform(X_train, y_train)\n",
    "    Xt_sample = Xt_train[:min(3000, Xt_train.shape[0])]\n",
    "    shap_values = explainer.shap_values(Xt_sample)\n",
    "    shap.summary_plot(shap_values, Xt_sample, plot_type=\"bar\", show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"shap_summary_plot.png\", dpi=200)\n",
    "    plt.close()\n",
    "else:\n",
    "    # Feature importance bar chart\n",
    "    model = pipe.named_steps[\"clf\"]\n",
    "    try:\n",
    "        importances = model.feature_importances_\n",
    "        # Cat feature names\n",
    "        cat_names = list(ohe.get_feature_names_out(cat_cols))\n",
    "        feat_names = numeric_cols + cat_names\n",
    "        imp_df = pd.DataFrame({\"feature\": feat_names, \"importance\": importances}).sort_values(\"importance\", ascending=False).head(20)\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.barh(imp_df[\"feature\"][::-1], imp_df[\"importance\"][::-1])\n",
    "        plt.title(\"Top 20 Feature Importances\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"shap_summary_plot.png\", dpi=200)\n",
    "        plt.close()\n",
    "    except Exception:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.text(0.5,0.5,\"Importance plot unavailable\", ha=\"center\", va=\"center\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(\"shap_summary_plot.png\", dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Power BI-ready aggregates\n",
    "# -----------------------------\n",
    "# 8.1 Summary metrics\n",
    "total_students = students_export[\"StudentID\"].nunique()\n",
    "high_risk_students = alerts_export.query(\"RiskLevel == 'High'\")[\"StudentID\"].nunique()\n",
    "high_risk_pct = (high_risk_students / total_students) * 100.0\n",
    "avg_attendance = enrollments_df[\"AttendanceRate\"].mean()\n",
    "# Pass rate: distinct students with max FinalExamScore >= PASS_MARK\n",
    "passers = assessments_df.groupby(\"StudentID\")[\"FinalExamScore\"].max().ge(PASS_MARK).sum()\n",
    "pass_rate_pct = (passers / total_students) * 100.0\n",
    "retention_lift_pct = (pass_rate_pct/100.0 - BASELINE_PASS_RATE) * 100.0\n",
    "\n",
    "pd.DataFrame([{\n",
    "    \"total_students\": int(total_students),\n",
    "    \"high_risk_%\": round(high_risk_pct, 1),\n",
    "    \"average_attendance\": round(avg_attendance, 1),\n",
    "    \"pass_rate_%\": round(pass_rate_pct, 1),\n",
    "    \"retention_lift_%\": round(retention_lift_pct, 1)\n",
    "}]).to_csv(\"summary_metrics.csv\", index=False)\n",
    "\n",
    "# 8.2 Risk trend (highest risk per student-week)\n",
    "trend = alerts_export.copy()\n",
    "trend[\"week\"] = pd.to_datetime(trend[\"AlertDate\"]).dt.to_period(\"W\").apply(lambda r: r.start_time)\n",
    "risk_priority = {\"High\": 3, \"Medium\": 2, \"Low\": 1}\n",
    "trend[\"risk_score\"] = trend[\"RiskLevel\"].map(risk_priority)\n",
    "trend_sorted = trend.sort_values([\"StudentID\",\"week\",\"risk_score\"], ascending=[True, True, False])\n",
    "trend_consolidated = trend_sorted.drop_duplicates(subset=[\"StudentID\",\"week\"], keep=\"first\")\n",
    "risk_trend = trend_consolidated.groupby([\"week\",\"RiskLevel\"])[\"StudentID\"].nunique().reset_index()\n",
    "risk_trend.columns = [\"week\",\"risk_level\",\"count\"]\n",
    "risk_trend.to_csv(\"risk_trend.csv\", index=False)\n",
    "\n",
    "# 8.3 Risk by dept & course (avoid duplicate Department columns)\n",
    "risk_by_dept_course = (\n",
    "    alerts_export\n",
    "      .merge(students_export[[\"StudentID\",\"Department\"]], on=\"StudentID\", how=\"left\")\n",
    "      .merge(courses_df[[\"CourseID\",\"CourseName\"]], on=\"CourseID\", how=\"left\")\n",
    "      .groupby([\"Department\",\"CourseName\",\"RiskLevel\"])[\"StudentID\"].nunique()\n",
    "      .reset_index()\n",
    "      .rename(columns={\n",
    "          \"Department\":\"department\",\n",
    "          \"CourseName\":\"course\",\n",
    "          \"RiskLevel\":\"risk_level\",\n",
    "          \"StudentID\":\"count\"\n",
    "      })\n",
    ")\n",
    "risk_by_dept_course.to_csv(\"risk_by_dept_course.csv\", index=False)\n",
    "\n",
    "# 8.4 Student 360 (avoid duplicate Department columns)\n",
    "student_360 = (\n",
    "    alerts_export\n",
    "      .merge(students_export[[\"StudentID\",\"Department\"]], on=\"StudentID\", how=\"left\")\n",
    "      .merge(courses_df[[\"CourseID\",\"CourseName\"]], on=\"CourseID\", how=\"left\")\n",
    "      .merge(enrollments_df, on=[\"StudentID\",\"CourseID\"], how=\"left\")\n",
    "      .merge(assessments_df, on=[\"StudentID\",\"CourseID\"], how=\"left\")\n",
    "      .merge(recs_export, on=[\"StudentID\",\"CourseID\"], how=\"left\")\n",
    "      .loc[:, [\"StudentID\",\"Department\",\"CourseName\",\"AttendanceRate\",\"IA1\",\"IA2\",\"IA3\",\n",
    "               \"FinalExamScore\",\"RiskLevel\",\"RecommendedAction\"]]\n",
    "      .rename(columns={\n",
    "          \"StudentID\":\"student_id\",\n",
    "          \"Department\":\"department\",\n",
    "          \"CourseName\":\"course\",\n",
    "          \"AttendanceRate\":\"attendance\",\n",
    "          \"FinalExamScore\":\"final_score\",\n",
    "          \"RiskLevel\":\"risk_level\",\n",
    "          \"RecommendedAction\":\"recommended_action\"\n",
    "      })\n",
    ")\n",
    "student_360.to_csv(\"student_360.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"- students.csv, courses.csv, enrollments.csv, assessments.csv, lms.csv\")\n",
    "print(\"- features.csv\")\n",
    "print(\"- alerts.csv\")\n",
    "print(\"- recommendations.csv\")\n",
    "print(\"- shap_summary_plot.png\")\n",
    "print(\"- student_perf_clf.joblib\")\n",
    "print(\"- summary_metrics.csv\")\n",
    "print(\"- risk_trend.csv\")\n",
    "print(\"- risk_by_dept_course.csv\")\n",
    "print(\"- student_360.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
